{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"OpenShift 101: Learn the Basics of Red Hat OpenShift on IBM Cloud \u00b6 A recent study by McKinsey & Company reveals that only 20 percent of enterprise applications have moved to the cloud. We believe that a hybrid cloud approach, built on open source and a vibrant open ecosystem, is the best way to move the remaining 80 percent. So what is OpenShift \u00b6 To quote Wikipedia: OpenShift is a family of containerization software developed by Red Hat. Its flagship product is the OpenShift Container Platform-an on-premises platform as a service built around Docker containers orchestrated and managed by Kubernetes on a foundation of Red Hat Enterprise Linux. The Openshift UI has various functionalities, allowing one to monitor the container resources, container health, the nodes the containers reside on, IP addresses of the nodes, etc. The key store can be accessed via the Secrets in Openshift. The OC CLI command line tool also offers similar functionalities. But the short of it? It's a abstraction layer ON TOP of Kubernetes. It's a way to empower Developers to deploy code and not worry about a lot of the underlying ecosystem. This workshop should show you the happy path to take advantage of most of the best parts of OpenShift and what it can offer. The goals of this workshop are: To familiarize the reader with OpenShift Deploy a Node.js application to OpenShift Use OpenShift's features to monitor, scale the application About this workshop \u00b6 The introductory page of the workshop is broken down into the following sections: Compatability Credits Compatability \u00b6 This workshop has been tested on the following platforms: macOS : Mojave (10.14), Catalina (10.15) Credits \u00b6 Many folks have contributed to help shape, test, and contribute the workshop. Spencer Krum JJ Asghar Tim Robinson Mofi Rahman Sai Vennam Steve Martinelli Ram Vennam Remko De Knikker Alex Parker Dewan Ahmed","title":"About the workshop"},{"location":"#openshift-101-learn-the-basics-of-red-hat-openshift-on-ibm-cloud","text":"A recent study by McKinsey & Company reveals that only 20 percent of enterprise applications have moved to the cloud. We believe that a hybrid cloud approach, built on open source and a vibrant open ecosystem, is the best way to move the remaining 80 percent.","title":"OpenShift 101: Learn the Basics of Red Hat OpenShift on IBM Cloud"},{"location":"#so-what-is-openshift","text":"To quote Wikipedia: OpenShift is a family of containerization software developed by Red Hat. Its flagship product is the OpenShift Container Platform-an on-premises platform as a service built around Docker containers orchestrated and managed by Kubernetes on a foundation of Red Hat Enterprise Linux. The Openshift UI has various functionalities, allowing one to monitor the container resources, container health, the nodes the containers reside on, IP addresses of the nodes, etc. The key store can be accessed via the Secrets in Openshift. The OC CLI command line tool also offers similar functionalities. But the short of it? It's a abstraction layer ON TOP of Kubernetes. It's a way to empower Developers to deploy code and not worry about a lot of the underlying ecosystem. This workshop should show you the happy path to take advantage of most of the best parts of OpenShift and what it can offer. The goals of this workshop are: To familiarize the reader with OpenShift Deploy a Node.js application to OpenShift Use OpenShift's features to monitor, scale the application","title":"So what is OpenShift"},{"location":"#about-this-workshop","text":"The introductory page of the workshop is broken down into the following sections: Compatability Credits","title":"About this workshop"},{"location":"#compatability","text":"This workshop has been tested on the following platforms: macOS : Mojave (10.14), Catalina (10.15)","title":"Compatability"},{"location":"#credits","text":"Many folks have contributed to help shape, test, and contribute the workshop. Spencer Krum JJ Asghar Tim Robinson Mofi Rahman Sai Vennam Steve Martinelli Ram Vennam Remko De Knikker Alex Parker Dewan Ahmed","title":"Credits"},{"location":"SUMMARY/","text":"Summary \u00b6 Getting Started \u00b6 Create an IBM Cloud account / Access an OpenShift cluster Accessing the IBM Cloud Shell Workshop \u00b6 Exercise 1: Deploy a Node application with Source-to-Image Exercise 2: Logging and monitoring Exercise 3: Metrics and dashboards Exercise 4: Scaling the application Exercise 5: Health checks Exercise 6: Deploy a Node application with Build Config (CLI version) Alternates \u00b6 Exercise 1: Deploy a Java application with a Docker Image Exercise 6: Deploy a Java application with Build Config (CLI version) Resources \u00b6 FAQ A General Docker Tutorial Kubernetes Overview Setup CLI Access for the cluster Certification on CognitiveClass.ai IBM Developer Docs: Red Hat OpenShift on IBM Cloud Survey \u00b6 Tell us how we did","title":"Summary"},{"location":"SUMMARY/#summary","text":"","title":"Summary"},{"location":"SUMMARY/#getting-started","text":"Create an IBM Cloud account / Access an OpenShift cluster Accessing the IBM Cloud Shell","title":"Getting Started"},{"location":"SUMMARY/#workshop","text":"Exercise 1: Deploy a Node application with Source-to-Image Exercise 2: Logging and monitoring Exercise 3: Metrics and dashboards Exercise 4: Scaling the application Exercise 5: Health checks Exercise 6: Deploy a Node application with Build Config (CLI version)","title":"Workshop"},{"location":"SUMMARY/#alternates","text":"Exercise 1: Deploy a Java application with a Docker Image Exercise 6: Deploy a Java application with Build Config (CLI version)","title":"Alternates"},{"location":"SUMMARY/#resources","text":"FAQ A General Docker Tutorial Kubernetes Overview Setup CLI Access for the cluster Certification on CognitiveClass.ai IBM Developer Docs: Red Hat OpenShift on IBM Cloud","title":"Resources"},{"location":"SUMMARY/#survey","text":"Tell us how we did","title":"Survey"},{"location":"99-faq/","text":"FAQ \u00b6 This page would list all know questions and potential problems, with possible answers or remedies. Upgrade your Trial account \u00b6 In 2018, IBM Cloud moved to a \"Lite\" account. If you have an old \"Trial\" account that expired after 30 days you should go to https://cloud.ibm.com/registration/startUpgradeToLite to freely convert your account to a \"Lite\" account. I can't create a new account \u00b6 Ask for whitelisting, or use your own smart phone with data plan (do not use local WiFi). I don't see OpenShift's Web Console \u00b6 Try restarting the VPN pod with the following command (log in to the environement using CLI token): kubectl delete pod -l app = vpn -n kube-system --wait = false I see an error while deploying my image to an internal container registry \u00b6 Try restarting the VPN with the following command: kubectl delete pod -l app = vpn -n kube-system --wait = false If that doesn't work please rebuild a cluster, or ask to get a new cluster.","title":"FAQ"},{"location":"99-faq/#faq","text":"This page would list all know questions and potential problems, with possible answers or remedies.","title":"FAQ"},{"location":"99-faq/#upgrade-your-trial-account","text":"In 2018, IBM Cloud moved to a \"Lite\" account. If you have an old \"Trial\" account that expired after 30 days you should go to https://cloud.ibm.com/registration/startUpgradeToLite to freely convert your account to a \"Lite\" account.","title":"Upgrade your Trial account"},{"location":"99-faq/#i-cant-create-a-new-account","text":"Ask for whitelisting, or use your own smart phone with data plan (do not use local WiFi).","title":"I can't create a new account"},{"location":"99-faq/#i-dont-see-openshifts-web-console","text":"Try restarting the VPN pod with the following command (log in to the environement using CLI token): kubectl delete pod -l app = vpn -n kube-system --wait = false","title":"I don't see OpenShift's Web Console"},{"location":"99-faq/#i-see-an-error-while-deploying-my-image-to-an-internal-container-registry","text":"Try restarting the VPN with the following command: kubectl delete pod -l app = vpn -n kube-system --wait = false If that doesn't work please rebuild a cluster, or ask to get a new cluster.","title":"I see an error while deploying my image to an internal container registry"},{"location":"exercise-01/","text":"Exercise 1: Deploy a Node application with Source-to-Image \u00b6 In this exercise, you'll deploy a simple Node.js Express application - \"Example Health\". Example Health is a simple UI for a patient health records system. We'll use this example to demonstrate key OpenShift features throughout this workshop. You can find the sample application GitHub repository here: https://github.com/IBM/node-s2i-openshift Deploy Example Health \u00b6 Access your cluster on the IBM Cloud clusters dashboard . Click the OpenShift web console button on the top-right. (This is a pop-up so you'll need to white list this site.) Here is the main dashboard you should see. Create a project, on the left hand side, you can title it whatever you like, we suggest \"example-health.\" And fill it out something like this. You should see a view that looks like this. Now click on Administrator and select Developer . Click on the From Catalog button. Scroll down and select Node.js Builder Image. If you don't see it, check Builder Image under Type . Click Create Application . You'll see an form like this: Enter the repository: https://github.com/IBM/node-s2i-openshift . Then click the Show Advanced Git Options and enter /site under Context Dir . Click 'Create' at the bottom of the window to build and deploy the application. Click on the center circle, then click \"Start Build.\" You should see #1 Build start. You can click on the \"View logs\" to get more details. When the build has deployed, find the \"Routes.\" Click on that link: And you should see the login screen like the following: You can enter any strings for username and password, for instance test:test because the app is running in demo mode. Congrats! You've deployed a Node.js app to Kubernetes using OpenShift Source-to-Image (S2I). Understanding What Happened \u00b6 S2I is a framework that creates container images from source code, then runs the assembled images as containers. It allows developers to build reproducible images easily, letting them spend time on what matters most, developing their code! Git Webhooks \u00b6 So far we have been doing a lot of manual deployment. In cloud-native world we want to move away from manual work and move toward automation. Wouldn't it be nice if our application rebuilt on git push events? Git webhooks are the way its done and openshift comes bundled in with git webhooks. Let's set it up for our project. To be able to setup git webhooks, we need to have elevated permission to the project. We don't own the repo we have been using so far. But since its opensource we can easily fork it and make it our own. Fork the repo at https://github.com/IBM/node-s2i-openshift Now that I have forked the repo under my repo I have full admin priviledges. As you can see I now have a settings button that I can change the repo settings with. We will come back to this page in a moment. Lets change our git source to our repo. From our openshift dashboard for our project. Select Builds Select the node-s-2-i-openshift build. As of now this should be the only build on screen. Click on Action on the right and then select Edit Build Config Change line 21 to Git Repository URL to our forked repository, and click Save . You will see this will not result in a new build. If you want to start a manual build you can do so by clicking Start Build . We will skip this for now and move on to the webhook part. Click on the Details tab. Scroll down and click Copy URL with Secret for the GitHub Webook URL. The webhook is in the structure https://c100-e.us-east.containers.cloud.ibm.com:31305/apis/build.openshift.io/v1/namespaces/example-health/buildconfigs/patientui/webhooks/<secret>/github There is also the generic webhook url. This also works for github. But the github webhook captures some additional data from github and is more specific. But if we were using some other git repo like bitbucket or gitlab we would use the generic one. In our github repo go to Setting > Webhooks . Then click Add Webhook In the Add Webhook page fill in the Payload URL with the url copied earlier from the build configuration. Change the Content type to application/json . NOTE : The Secret field can remain empty. Right now just the push event is being sent which is fine for our use. Click on Add webhook If the webhook is reachable by github you will see a green check mark. Back in our Openshift Console we still would only see one build however. Because we added a webhook that sends us push events and we have no push event happening. Lets make one. The easiest way to do it is probably from the Github UI. Lets change some text in the login page. Path to this file is site/public/login.html from the root of the directory. On Github you can edit any file by clicking the Pencil icon on the top right corner. Let's change the name our application to Demo Health (Line 21, Line 22). Feel free to make any other UI changes you feel like. Once done go to the bottom and click commit changes . Go to the Openshift Console and click on the Builds tab. This happens quite fast so you might not see the running state. But the moment we made that commit a new build was kicked off. In a moment it will show completed. Navigate to the Topology -> Application to find the route. You could also go to Applications > Routes to find the route for the application. If you go to your new route you will see your change.","title":"Lab 1. Deploy a Node app with Source-to-Image"},{"location":"exercise-01/#exercise-1-deploy-a-node-application-with-source-to-image","text":"In this exercise, you'll deploy a simple Node.js Express application - \"Example Health\". Example Health is a simple UI for a patient health records system. We'll use this example to demonstrate key OpenShift features throughout this workshop. You can find the sample application GitHub repository here: https://github.com/IBM/node-s2i-openshift","title":"Exercise 1: Deploy a Node application with Source-to-Image"},{"location":"exercise-01/#deploy-example-health","text":"Access your cluster on the IBM Cloud clusters dashboard . Click the OpenShift web console button on the top-right. (This is a pop-up so you'll need to white list this site.) Here is the main dashboard you should see. Create a project, on the left hand side, you can title it whatever you like, we suggest \"example-health.\" And fill it out something like this. You should see a view that looks like this. Now click on Administrator and select Developer . Click on the From Catalog button. Scroll down and select Node.js Builder Image. If you don't see it, check Builder Image under Type . Click Create Application . You'll see an form like this: Enter the repository: https://github.com/IBM/node-s2i-openshift . Then click the Show Advanced Git Options and enter /site under Context Dir . Click 'Create' at the bottom of the window to build and deploy the application. Click on the center circle, then click \"Start Build.\" You should see #1 Build start. You can click on the \"View logs\" to get more details. When the build has deployed, find the \"Routes.\" Click on that link: And you should see the login screen like the following: You can enter any strings for username and password, for instance test:test because the app is running in demo mode. Congrats! You've deployed a Node.js app to Kubernetes using OpenShift Source-to-Image (S2I).","title":"Deploy Example Health"},{"location":"exercise-01/#understanding-what-happened","text":"S2I is a framework that creates container images from source code, then runs the assembled images as containers. It allows developers to build reproducible images easily, letting them spend time on what matters most, developing their code!","title":"Understanding What Happened"},{"location":"exercise-01/#git-webhooks","text":"So far we have been doing a lot of manual deployment. In cloud-native world we want to move away from manual work and move toward automation. Wouldn't it be nice if our application rebuilt on git push events? Git webhooks are the way its done and openshift comes bundled in with git webhooks. Let's set it up for our project. To be able to setup git webhooks, we need to have elevated permission to the project. We don't own the repo we have been using so far. But since its opensource we can easily fork it and make it our own. Fork the repo at https://github.com/IBM/node-s2i-openshift Now that I have forked the repo under my repo I have full admin priviledges. As you can see I now have a settings button that I can change the repo settings with. We will come back to this page in a moment. Lets change our git source to our repo. From our openshift dashboard for our project. Select Builds Select the node-s-2-i-openshift build. As of now this should be the only build on screen. Click on Action on the right and then select Edit Build Config Change line 21 to Git Repository URL to our forked repository, and click Save . You will see this will not result in a new build. If you want to start a manual build you can do so by clicking Start Build . We will skip this for now and move on to the webhook part. Click on the Details tab. Scroll down and click Copy URL with Secret for the GitHub Webook URL. The webhook is in the structure https://c100-e.us-east.containers.cloud.ibm.com:31305/apis/build.openshift.io/v1/namespaces/example-health/buildconfigs/patientui/webhooks/<secret>/github There is also the generic webhook url. This also works for github. But the github webhook captures some additional data from github and is more specific. But if we were using some other git repo like bitbucket or gitlab we would use the generic one. In our github repo go to Setting > Webhooks . Then click Add Webhook In the Add Webhook page fill in the Payload URL with the url copied earlier from the build configuration. Change the Content type to application/json . NOTE : The Secret field can remain empty. Right now just the push event is being sent which is fine for our use. Click on Add webhook If the webhook is reachable by github you will see a green check mark. Back in our Openshift Console we still would only see one build however. Because we added a webhook that sends us push events and we have no push event happening. Lets make one. The easiest way to do it is probably from the Github UI. Lets change some text in the login page. Path to this file is site/public/login.html from the root of the directory. On Github you can edit any file by clicking the Pencil icon on the top right corner. Let's change the name our application to Demo Health (Line 21, Line 22). Feel free to make any other UI changes you feel like. Once done go to the bottom and click commit changes . Go to the Openshift Console and click on the Builds tab. This happens quite fast so you might not see the running state. But the moment we made that commit a new build was kicked off. In a moment it will show completed. Navigate to the Topology -> Application to find the route. You could also go to Applications > Routes to find the route for the application. If you go to your new route you will see your change.","title":"Git Webhooks"},{"location":"exercise-01b/","text":"Exercise 1: Deploy a Java application with a Docker Image \u00b6 In this exercise, you'll deploy a simple Java microservice - \"Authors\" from a public image registry to OpenShift. You can find the image on Docker Hub here: https://hub.docker.com/r/nheidloff/authors Deploy Authors application \u00b6 Access your cluster on the IBM Cloud clusters dashboard . Click the OpenShift web console button on the top-right. (This is a pop-up so you'll need to white list this site.) Create a project, you can title it whatever you like, we suggest \"example-authors.\" Click on your new project. You should see a view that looks like the image below. Click on the Deploy Image button on the main screen, or click on the Add to Project button and choose Deploy Image from there. At the pop up, choose the Image Name option. Enter nheidloff/authors:v1 as the image name and click the search icon. Once the image metadata loads click the Deploy button. At the application overview page, click the Create Route option. This will give our application an external URL. The default options are sufficient, scroll down to the bottom and click the Create button. Try to launch the application by copying the route's URL and appending /openapi/ui . {% hint style=\"info\" %} Add /openapi/ui to the URL! The Open API user interface for our Authors service will load. We can test the application by clicking the GET /v1/getauthor API. Choose the Try it out button and entering \"Niklas Heidloff\" as the query. Congratulations! You just deployed an image from a public registry aviable from Docker Hub.","title":"Lab 1b. Deploy a Java app with a Docker Image"},{"location":"exercise-01b/#exercise-1-deploy-a-java-application-with-a-docker-image","text":"In this exercise, you'll deploy a simple Java microservice - \"Authors\" from a public image registry to OpenShift. You can find the image on Docker Hub here: https://hub.docker.com/r/nheidloff/authors","title":"Exercise 1: Deploy a Java application with a Docker Image"},{"location":"exercise-01b/#deploy-authors-application","text":"Access your cluster on the IBM Cloud clusters dashboard . Click the OpenShift web console button on the top-right. (This is a pop-up so you'll need to white list this site.) Create a project, you can title it whatever you like, we suggest \"example-authors.\" Click on your new project. You should see a view that looks like the image below. Click on the Deploy Image button on the main screen, or click on the Add to Project button and choose Deploy Image from there. At the pop up, choose the Image Name option. Enter nheidloff/authors:v1 as the image name and click the search icon. Once the image metadata loads click the Deploy button. At the application overview page, click the Create Route option. This will give our application an external URL. The default options are sufficient, scroll down to the bottom and click the Create button. Try to launch the application by copying the route's URL and appending /openapi/ui . {% hint style=\"info\" %} Add /openapi/ui to the URL! The Open API user interface for our Authors service will load. We can test the application by clicking the GET /v1/getauthor API. Choose the Try it out button and entering \"Niklas Heidloff\" as the query. Congratulations! You just deployed an image from a public registry aviable from Docker Hub.","title":"Deploy Authors application"},{"location":"exercise-02/","text":"Exercise 2: Logging and monitoring \u00b6 In this exercise, we'll explore the out-of-the-box logging and monitoring capabilities that are offered in OpenShift. Simulate Load on the Application \u00b6 First, let's simulate some load on our application. Run the following script which will endlessly spam our app with requests: With Linux/MacOS while sleep 1 ; do curl -s <your_app_route>/info ; done With Windows while ( $true ){ curl <your_app_route>/info } {% hint style=\"info\" %} Note: Retrieve the external URL from the OpenShift console, or from the URL of your Example Health application. Note that there may be an /index.html at the end that you need to replace with /info . We're hitting the /info endpoint which will trigger some logs from our app. For example: http://patientui-health-example.myopenshift-xxx.us-east.containers.appdomain.cloud/info OpenShift Logging \u00b6 Since we only created one pod, seeing our logs will be straight forward. Navigate to View Logs on the left on the main dashboard. You should be taken to something like the following. Scroll up and you should see the DEBUG like in the image. Scroll back down, and you should see a new line every second per the curl above. OpenShift Terminal \u00b6 One of the great things about Kubernetes is the ability to quickly debug your application pods with SSH terminals. This is great for development, but generally is not recommended in production environments. OpenShift makes it even easier by allowing you to launch a terminal directly in the dashboard. Switch to the Terminal tab, and run the following commands. # This command shows you the the project files. ls # This command shows you the running processes. ps aux OpenShift Monitoring \u00b6 When deploying new apps, making configuration changes, or simply inspecting the state of your cluster, the OpenShift monitoring dashboard gives you an overview of your running assets. You can also dive in a bit deeper - the Events tab is very useful for identifying the timeline of events and finding potential error messages. You'll want to refer to this view throughout the lab. Almost all actions we take in in OpenShift will result in an event being fired in this view. As it is updated real-time, it's a great way to track changes to state.","title":"Lab 2. Logging and monitoring"},{"location":"exercise-02/#exercise-2-logging-and-monitoring","text":"In this exercise, we'll explore the out-of-the-box logging and monitoring capabilities that are offered in OpenShift.","title":"Exercise 2: Logging and monitoring"},{"location":"exercise-02/#simulate-load-on-the-application","text":"First, let's simulate some load on our application. Run the following script which will endlessly spam our app with requests: With Linux/MacOS while sleep 1 ; do curl -s <your_app_route>/info ; done With Windows while ( $true ){ curl <your_app_route>/info } {% hint style=\"info\" %} Note: Retrieve the external URL from the OpenShift console, or from the URL of your Example Health application. Note that there may be an /index.html at the end that you need to replace with /info . We're hitting the /info endpoint which will trigger some logs from our app. For example: http://patientui-health-example.myopenshift-xxx.us-east.containers.appdomain.cloud/info","title":"Simulate Load on the Application"},{"location":"exercise-02/#openshift-logging","text":"Since we only created one pod, seeing our logs will be straight forward. Navigate to View Logs on the left on the main dashboard. You should be taken to something like the following. Scroll up and you should see the DEBUG like in the image. Scroll back down, and you should see a new line every second per the curl above.","title":"OpenShift Logging"},{"location":"exercise-02/#openshift-terminal","text":"One of the great things about Kubernetes is the ability to quickly debug your application pods with SSH terminals. This is great for development, but generally is not recommended in production environments. OpenShift makes it even easier by allowing you to launch a terminal directly in the dashboard. Switch to the Terminal tab, and run the following commands. # This command shows you the the project files. ls # This command shows you the running processes. ps aux","title":"OpenShift Terminal"},{"location":"exercise-02/#openshift-monitoring","text":"When deploying new apps, making configuration changes, or simply inspecting the state of your cluster, the OpenShift monitoring dashboard gives you an overview of your running assets. You can also dive in a bit deeper - the Events tab is very useful for identifying the timeline of events and finding potential error messages. You'll want to refer to this view throughout the lab. Almost all actions we take in in OpenShift will result in an event being fired in this view. As it is updated real-time, it's a great way to track changes to state.","title":"OpenShift Monitoring"},{"location":"exercise-03/","text":"Exercise 3: Metrics and dashboards \u00b6 In this exercise, we'll explore the third-party monitoring and metrics dashboards that are installed for free with OpenShift! Grafana \u00b6 Red Hat OpenShift on IBM Cloud comes with Grafana preinstalled. Get started by switching to the Administrator view: Then Navigate to Monitoring > Dashboards in the left-hand bar. Then click on Grafana UI next to the title. You'll be asked to login with OpenShift and then click through some permissions. This will open up another proxy page, click Log in with OpenShift . Next, it will ask you for Authorize Access , take the default which is both checkboxes, and click Allow selected permissions . You should then see your Grafana dashboard. Hit Home on the top left, and choose Kubernetes / Compute Resources / Namespace (Pods) . Under namespace , choose the name of the project you created in Step 1 - the same one that your application is running inside. You should be able to see the CPU and Memory usage for your application. In production environments, this is helpful for identifying the average amount of CPU or Memory your application uses, especially as it can fluctuate through the day. We'll use this information in the next exercise to set up auto-scaling for our pods. Prometheus and Alert Manager \u00b6 Navigating back to the cluster console, you can also launch Alerting and Metrics UIs Prometheus - a monitoring system with an efficient time series database Alertmanager - an extension of Prometheus focused on managing alerts Prometheus \u00b6 Alertmanager \u00b6","title":"Lab 3. Metrics and dashboards"},{"location":"exercise-03/#exercise-3-metrics-and-dashboards","text":"In this exercise, we'll explore the third-party monitoring and metrics dashboards that are installed for free with OpenShift!","title":"Exercise 3: Metrics and dashboards"},{"location":"exercise-03/#grafana","text":"Red Hat OpenShift on IBM Cloud comes with Grafana preinstalled. Get started by switching to the Administrator view: Then Navigate to Monitoring > Dashboards in the left-hand bar. Then click on Grafana UI next to the title. You'll be asked to login with OpenShift and then click through some permissions. This will open up another proxy page, click Log in with OpenShift . Next, it will ask you for Authorize Access , take the default which is both checkboxes, and click Allow selected permissions . You should then see your Grafana dashboard. Hit Home on the top left, and choose Kubernetes / Compute Resources / Namespace (Pods) . Under namespace , choose the name of the project you created in Step 1 - the same one that your application is running inside. You should be able to see the CPU and Memory usage for your application. In production environments, this is helpful for identifying the average amount of CPU or Memory your application uses, especially as it can fluctuate through the day. We'll use this information in the next exercise to set up auto-scaling for our pods.","title":"Grafana"},{"location":"exercise-03/#prometheus-and-alert-manager","text":"Navigating back to the cluster console, you can also launch Alerting and Metrics UIs Prometheus - a monitoring system with an efficient time series database Alertmanager - an extension of Prometheus focused on managing alerts","title":"Prometheus and Alert Manager"},{"location":"exercise-03/#prometheus","text":"","title":"Prometheus"},{"location":"exercise-03/#alertmanager","text":"","title":"Alertmanager"},{"location":"exercise-04/","text":"Exercise 4: Scaling the application \u00b6 In this exercise, we'll leverage the metrics we've observed in the previous step to automatically scale our UI application in response to load. Enable Resource Limits \u00b6 Before we can setup autoscaling for our pods, we first need to set resource limits on the pods running in our cluster. Limits allows you to choose the minimum and maximum CPU and memory usage for a pod. Hopefully you have your running script simulating load \\(if not go [here](../exercise-02#simulate-load-on-the-application)\\) , Grafana showed you that your application was consuming anywhere between \".002\" to \".02\" cores. This translates to 2-20 \"millicores\". That seems like a good range for our CPU request, but to be safe, let's bump the higher-end up to 30 millicores. In addition, Grafana showed that the app consumes about 25 - 35 MB of RAM. Set the following resource limits for your deployment now. Switch to the Administrator view and then navigate to Workloads > Deployments in the left-hand bar. Choose the patient-ui Deployment, then choose Actions > Edit Deployment . In the YAML editor, go to line 44. In the section template > spec > containers , add the following resource limits into the empty resources. Replace the resources {} , and ensure the spacing is correct -- YAML uses strict indentation. resources : limits : cpu : 30m memory : 100Mi requests : cpu : 3m memory : 40Mi Save and Reload to see the new version. Verify that the replication controller has been changed by navigating to Events Enable Autoscaler \u00b6 Now that we have resource limits, let's enable autoscaler. By default, the autoscaler allows you to scale based on CPU or Memory. The UI allows you to do CPU only \\(for now\\) . Pods are balanced between the minifmum and maximum number of pods that you specify. With the autoscaler, pods are automatically created or deleted to ensure that the average CPU usage of the pods is below the CPU request target as defined. In general, you probably want to start scaling up when you get near 50 - 90 % of the CPU usage of a pod. In our case, let's make it 1 % to test the autoscaler since we are generating minimal load. Navigate to Workloads > Horizontal Pod Autoscalers , then hit Create Horizontal Pod Autoscaler . apiVersion : autoscaling/v2beta1 kind : HorizontalPodAutoscaler metadata : name : patient-hpa namespace : example-health spec : scaleTargetRef : apiVersion : apps/v1 kind : Deployment name : patient-ui minReplicas : 1 maxReplicas : 10 metrics : - type : Resource resource : name : cpu targetAverageUtilization : 1 Hit Create . Test Autoscaler \u00b6 If you're not running the script from the previous exercise , the number of pods should stay at 1. Check by going to the Overview page of Deployments . Start simulating load by hitting the page several times, or running the script. You'll see that it starts to scale up: That's it! You now have a highly available and automatically scaled front-end Node.js application. OpenShift is automatically scaling your application pods since the CPU usage of the pods greatly exceeded 1 % of the resource limit, 30 millicores. Optional \u00b6 If you're interested in setting up the CLI, follow the steps here . Then, run the following command in your CLI oc get hpa to get information about your horizontal pod autoscaler. Remember to switch to your project first with oc project <project-name> . You could have created the autoscaler with the command oc autoscale deployment/patient-ui --min 1 --max 10 --cpu-percent=1 .","title":"Lab 4. Scaling the application"},{"location":"exercise-04/#exercise-4-scaling-the-application","text":"In this exercise, we'll leverage the metrics we've observed in the previous step to automatically scale our UI application in response to load.","title":"Exercise 4: Scaling the application"},{"location":"exercise-04/#enable-resource-limits","text":"Before we can setup autoscaling for our pods, we first need to set resource limits on the pods running in our cluster. Limits allows you to choose the minimum and maximum CPU and memory usage for a pod. Hopefully you have your running script simulating load \\(if not go [here](../exercise-02#simulate-load-on-the-application)\\) , Grafana showed you that your application was consuming anywhere between \".002\" to \".02\" cores. This translates to 2-20 \"millicores\". That seems like a good range for our CPU request, but to be safe, let's bump the higher-end up to 30 millicores. In addition, Grafana showed that the app consumes about 25 - 35 MB of RAM. Set the following resource limits for your deployment now. Switch to the Administrator view and then navigate to Workloads > Deployments in the left-hand bar. Choose the patient-ui Deployment, then choose Actions > Edit Deployment . In the YAML editor, go to line 44. In the section template > spec > containers , add the following resource limits into the empty resources. Replace the resources {} , and ensure the spacing is correct -- YAML uses strict indentation. resources : limits : cpu : 30m memory : 100Mi requests : cpu : 3m memory : 40Mi Save and Reload to see the new version. Verify that the replication controller has been changed by navigating to Events","title":"Enable Resource Limits"},{"location":"exercise-04/#enable-autoscaler","text":"Now that we have resource limits, let's enable autoscaler. By default, the autoscaler allows you to scale based on CPU or Memory. The UI allows you to do CPU only \\(for now\\) . Pods are balanced between the minifmum and maximum number of pods that you specify. With the autoscaler, pods are automatically created or deleted to ensure that the average CPU usage of the pods is below the CPU request target as defined. In general, you probably want to start scaling up when you get near 50 - 90 % of the CPU usage of a pod. In our case, let's make it 1 % to test the autoscaler since we are generating minimal load. Navigate to Workloads > Horizontal Pod Autoscalers , then hit Create Horizontal Pod Autoscaler . apiVersion : autoscaling/v2beta1 kind : HorizontalPodAutoscaler metadata : name : patient-hpa namespace : example-health spec : scaleTargetRef : apiVersion : apps/v1 kind : Deployment name : patient-ui minReplicas : 1 maxReplicas : 10 metrics : - type : Resource resource : name : cpu targetAverageUtilization : 1 Hit Create .","title":"Enable Autoscaler"},{"location":"exercise-04/#test-autoscaler","text":"If you're not running the script from the previous exercise , the number of pods should stay at 1. Check by going to the Overview page of Deployments . Start simulating load by hitting the page several times, or running the script. You'll see that it starts to scale up: That's it! You now have a highly available and automatically scaled front-end Node.js application. OpenShift is automatically scaling your application pods since the CPU usage of the pods greatly exceeded 1 % of the resource limit, 30 millicores.","title":"Test Autoscaler"},{"location":"exercise-04/#optional","text":"If you're interested in setting up the CLI, follow the steps here . Then, run the following command in your CLI oc get hpa to get information about your horizontal pod autoscaler. Remember to switch to your project first with oc project <project-name> . You could have created the autoscaler with the command oc autoscale deployment/patient-ui --min 1 --max 10 --cpu-percent=1 .","title":"Optional"},{"location":"exercise-05/","text":"Exercise 5: Health checks \u00b6 In Kubernetes, liveness and readiness probes are essential for smoothly running applications. A probe is generally a REST GET call, but there are other types of probes available. Liveness probes are used to determine when to restart a container. For example, an application that is unhealthy and no longer responding to an API call would be restarted by OpenShift. Readiness probes determine when a container is ready to start receiving traffic. If a readiness probe fails, then the load balancer would deregister that service. Create Readiness and Liveness Probes \u00b6 The /info endpoint on the Example Health application is a great way to check whether the application is running and responding to API calls -- it responds with a simple JSON payload. Go ahead and click on the deployment view. You should see something like node-s-2-i-openshift . Click Actions > Edit Deployment . Find the containers line probably line 38 . Under the resources line, so line 46 past the following yaml . This will add a liveness probe to your deployment! livenessProbe : initialDelaySeconds : 5 periodSeconds : 2 httpGet : path : /info port : 8080 Now, next step is to add a readiness probe. Luckly it's on the same page, imediatly under the livenessProbe stanza you entered, paste the following: readinessProbe : initialDelaySeconds : 5 timeoutSeconds : 2 httpGet : path : /info port : 8080 This will make sure when a new deployment happens that it won't start until the /info path is available. If you want to verify it, you can run the following command to check the status, you should see something like this in the output: oc describe deployment node-s-2-i-openshift Liveness: http-get http://:8080/info delay=5s timeout=1s period=2s #success=1 #failure=3 Readiness: http-get http://:8080/info delay=5s timeout=2s period=10s #success=1 #failure=3 If all works, everything should be the same. Let's check that the probes are really working though. Inject Failure \u00b6 Let's edit the probe with a typo to see what happens when it fails. Edit the health check and change the path for the readiness probe to /badpath . Wait a few minutes and check your deployment - you'll notice that 0/1 containers are ready: Dive into your events and you'll see that the probe is failing, causing the platform to try and repeatedly restart your pod. Using health checks gives your OpenShift service layer better reliability and helps you start with a strong foundation.","title":"Lab 5. Health checks"},{"location":"exercise-05/#exercise-5-health-checks","text":"In Kubernetes, liveness and readiness probes are essential for smoothly running applications. A probe is generally a REST GET call, but there are other types of probes available. Liveness probes are used to determine when to restart a container. For example, an application that is unhealthy and no longer responding to an API call would be restarted by OpenShift. Readiness probes determine when a container is ready to start receiving traffic. If a readiness probe fails, then the load balancer would deregister that service.","title":"Exercise 5: Health checks"},{"location":"exercise-05/#create-readiness-and-liveness-probes","text":"The /info endpoint on the Example Health application is a great way to check whether the application is running and responding to API calls -- it responds with a simple JSON payload. Go ahead and click on the deployment view. You should see something like node-s-2-i-openshift . Click Actions > Edit Deployment . Find the containers line probably line 38 . Under the resources line, so line 46 past the following yaml . This will add a liveness probe to your deployment! livenessProbe : initialDelaySeconds : 5 periodSeconds : 2 httpGet : path : /info port : 8080 Now, next step is to add a readiness probe. Luckly it's on the same page, imediatly under the livenessProbe stanza you entered, paste the following: readinessProbe : initialDelaySeconds : 5 timeoutSeconds : 2 httpGet : path : /info port : 8080 This will make sure when a new deployment happens that it won't start until the /info path is available. If you want to verify it, you can run the following command to check the status, you should see something like this in the output: oc describe deployment node-s-2-i-openshift Liveness: http-get http://:8080/info delay=5s timeout=1s period=2s #success=1 #failure=3 Readiness: http-get http://:8080/info delay=5s timeout=2s period=10s #success=1 #failure=3 If all works, everything should be the same. Let's check that the probes are really working though.","title":"Create Readiness and Liveness Probes"},{"location":"exercise-05/#inject-failure","text":"Let's edit the probe with a typo to see what happens when it fails. Edit the health check and change the path for the readiness probe to /badpath . Wait a few minutes and check your deployment - you'll notice that 0/1 containers are ready: Dive into your events and you'll see that the probe is failing, causing the platform to try and repeatedly restart your pod. Using health checks gives your OpenShift service layer better reliability and helps you start with a strong foundation.","title":"Inject Failure"},{"location":"exercise-06/","text":"Exercise 6: Deploy a Node application with Build Config (CLI version) \u00b6 In this exercise we'll revisit the application from exercise 1, except we'll use equivalent CLI commands to deploy our \"Example Health\" application. From the IBM Cloud console launch the IBM Cloud Shell. Refer to our Getting Starting material to learn how to access the IBM Cloud Shell. Deploy Example Health (CLI version) \u00b6 First, clone the Example Health source code and change to that directory. git clone https://github.com/IBM/node-build-config-openshift cd node-build-config-openshift Take note of the new Dockerfile in the application's root directory. We've pre-written it for you. But we've copied it here too, go through each line and read the corresponding comment. # Use the official Node 10 image FROM node:10 # Change directory to /usr/src/app WORKDIR /usr/src/app # Copy the application source code COPY . . # Change directory to site/ WORKDIR site/ # Install dependencies RUN npm install # Allow traffic on port 8080 EXPOSE 8080 # Start the application CMD [ \"npm\" , \"start\" ] From the OpenShift console click the user name in the top right corner and select Copy Login Command . The login command will be copied to the clipboard, in the IBM Cloud Shell, paste that command. For example: oc login https://c100-e.us-south.containers.cloud.ibm.com:30403 --token = jWX7a04tRgpdhW_iofWuHqb_Ygp8fFsUkRjOK7_QyFQ Create a new OpenShift project to deploy our application, call it example-health-ns . oc new-project example-health-ns Build your application's image by running the oc new-build command from your source code root directory. This will create a Build and an ImageStream of the app. oc new-build --strategy docker --binary --docker-image node:10 --name example-health The output should look like below: oc new-build --strategy docker --binary --docker-image node:10 --name example-health --> Found Docker image aa64327 ( 3 weeks old ) from Docker Hub for \"node:10\" * An image stream tag will be created as \"node:10\" that will track the source image * A Docker build using binary input will be created * The resulting image will be pushed to image stream tag \"example-health:latest\" * A binary build was created, use 'start-build --from-dir' to trigger a new build --> Creating resources with label build = example-health ... imagestream.image.openshift.io \"node\" created imagestream.image.openshift.io \"example-health\" created buildconfig.build.openshift.io \"example-health\" created --> Success Start a new build using the oc start-build command. oc start-build example-health --from-dir . --follow The output should look like below: oc start-build example-health --from-dir . --follow Uploading directory \".\" as binary input for the build ... . Uploading finished build.build.openshift.io/example-health-1 started Receiving source from STDIN as archive ... Replaced Dockerfile FROM image node:10 ... Successfully built 11bff161eb8e Pushing image docker-registry.default.svc:5000/example-health-ns/example-health:latest ... Pushed 0 /12 layers, 17 % complete Pushed 1 /12 layers, 42 % complete ... Pushed 11 /12 layers, 100 % complete Pushed 12 /12 layers, 100 % complete Finally, deploy the application by running oc new-app . oc new-app -i example-health The output should look like below: $ oc new-app -i example-health --> Found image 11bff16 ( 8 minutes old ) in image stream \"example-health-ns/example-health\" under tag \"latest\" for \"example-health\" * This image will be deployed in deployment config \"example-health\" * Port 8080 /tcp will be load balanced by service \"example-health\" * Other containers can access this service through the hostname \"example-health\" * WARNING: Image \"example-health-ns/example-health:latest\" runs as the 'root' user which may not be permitted by your cluster administrator --> Creating resources ... deploymentconfig.apps.openshift.io \"example-health\" created service \"example-health\" created --> Success Application is not exposed. You can expose services to the outside world by executing one or more of the commands below: 'oc expose svc/example-health' Run 'oc status' to view your app. Expose the service using oc expose , a route will be created. oc expose svc/example-health Find the application's route by running oc get routes . oc get routes The output should look like below: $ oc get routes NAME HOST/PORT PATH SERVICES PORT TERMINATION WILDCARD example-health example-health-example-health-ns.aida-dev-apps-10-30-f2c6cdc6801be85fd188b09d006f13e3-0001.us-south.containers.appdomain.cloud example-health 8080 -tcp None Copy the URL into a browser and log into the site with admin : test . Congratulations on completing this exercise!","title":"Lab 6. Deploy a Node app with Build Config (CLI)"},{"location":"exercise-06/#exercise-6-deploy-a-node-application-with-build-config-cli-version","text":"In this exercise we'll revisit the application from exercise 1, except we'll use equivalent CLI commands to deploy our \"Example Health\" application. From the IBM Cloud console launch the IBM Cloud Shell. Refer to our Getting Starting material to learn how to access the IBM Cloud Shell.","title":"Exercise 6: Deploy a Node application with Build Config (CLI version)"},{"location":"exercise-06/#deploy-example-health-cli-version","text":"First, clone the Example Health source code and change to that directory. git clone https://github.com/IBM/node-build-config-openshift cd node-build-config-openshift Take note of the new Dockerfile in the application's root directory. We've pre-written it for you. But we've copied it here too, go through each line and read the corresponding comment. # Use the official Node 10 image FROM node:10 # Change directory to /usr/src/app WORKDIR /usr/src/app # Copy the application source code COPY . . # Change directory to site/ WORKDIR site/ # Install dependencies RUN npm install # Allow traffic on port 8080 EXPOSE 8080 # Start the application CMD [ \"npm\" , \"start\" ] From the OpenShift console click the user name in the top right corner and select Copy Login Command . The login command will be copied to the clipboard, in the IBM Cloud Shell, paste that command. For example: oc login https://c100-e.us-south.containers.cloud.ibm.com:30403 --token = jWX7a04tRgpdhW_iofWuHqb_Ygp8fFsUkRjOK7_QyFQ Create a new OpenShift project to deploy our application, call it example-health-ns . oc new-project example-health-ns Build your application's image by running the oc new-build command from your source code root directory. This will create a Build and an ImageStream of the app. oc new-build --strategy docker --binary --docker-image node:10 --name example-health The output should look like below: oc new-build --strategy docker --binary --docker-image node:10 --name example-health --> Found Docker image aa64327 ( 3 weeks old ) from Docker Hub for \"node:10\" * An image stream tag will be created as \"node:10\" that will track the source image * A Docker build using binary input will be created * The resulting image will be pushed to image stream tag \"example-health:latest\" * A binary build was created, use 'start-build --from-dir' to trigger a new build --> Creating resources with label build = example-health ... imagestream.image.openshift.io \"node\" created imagestream.image.openshift.io \"example-health\" created buildconfig.build.openshift.io \"example-health\" created --> Success Start a new build using the oc start-build command. oc start-build example-health --from-dir . --follow The output should look like below: oc start-build example-health --from-dir . --follow Uploading directory \".\" as binary input for the build ... . Uploading finished build.build.openshift.io/example-health-1 started Receiving source from STDIN as archive ... Replaced Dockerfile FROM image node:10 ... Successfully built 11bff161eb8e Pushing image docker-registry.default.svc:5000/example-health-ns/example-health:latest ... Pushed 0 /12 layers, 17 % complete Pushed 1 /12 layers, 42 % complete ... Pushed 11 /12 layers, 100 % complete Pushed 12 /12 layers, 100 % complete Finally, deploy the application by running oc new-app . oc new-app -i example-health The output should look like below: $ oc new-app -i example-health --> Found image 11bff16 ( 8 minutes old ) in image stream \"example-health-ns/example-health\" under tag \"latest\" for \"example-health\" * This image will be deployed in deployment config \"example-health\" * Port 8080 /tcp will be load balanced by service \"example-health\" * Other containers can access this service through the hostname \"example-health\" * WARNING: Image \"example-health-ns/example-health:latest\" runs as the 'root' user which may not be permitted by your cluster administrator --> Creating resources ... deploymentconfig.apps.openshift.io \"example-health\" created service \"example-health\" created --> Success Application is not exposed. You can expose services to the outside world by executing one or more of the commands below: 'oc expose svc/example-health' Run 'oc status' to view your app. Expose the service using oc expose , a route will be created. oc expose svc/example-health Find the application's route by running oc get routes . oc get routes The output should look like below: $ oc get routes NAME HOST/PORT PATH SERVICES PORT TERMINATION WILDCARD example-health example-health-example-health-ns.aida-dev-apps-10-30-f2c6cdc6801be85fd188b09d006f13e3-0001.us-south.containers.appdomain.cloud example-health 8080 -tcp None Copy the URL into a browser and log into the site with admin : test . Congratulations on completing this exercise!","title":"Deploy Example Health (CLI version)"},{"location":"exercise-06b/","text":"Exercise 6b: Deploy a Java application with Build Config (CLI version) \u00b6 In this exercise we'll revisit the application from exercise 1, except we'll use equivalent CLI commands to deploy our \"Authors\" application. From the IBM Cloud console launch the IBM Cloud Shell. Refer to our Getting Starting material to learn how to access the IBM Cloud Shell. Deploy Authors application (CLI version) \u00b6 First, clone the Authors source code and change to that directory. git clone https://github.com/IBM/openshift-on-ibm-cloud-workshops cd openshift-on-ibm-cloud-workshops cd deploying-to-openshift Take note of the new Dockerfile in the application's directory. We've pre-written it for you. But we've copied it here too, go through each line and read the corresponding comment. # Use an official JDK image FROM maven:3.5-jdk-8 as BUILD # Copy the application source code COPY src /usr/src/app/src COPY pom.xml /usr/src/app # Run maven to build the application RUN mvn -f /usr/src/app/pom.xml clean package FROM open-liberty:microProfile2-java11 COPY liberty/server.xml /config/ COPY --from = BUILD /usr/src/app/target/authors.war /config/apps/ # Allow traffic on port 3000 EXPOSE 3000 From the OpenShift console click the user name in the top right corner and select Copy Login Command . The login command will be copied to the clipboard, in the IBM Cloud Shell, paste that command. For example: oc login https://c100-e.us-south.containers.cloud.ibm.com:30403 --token = jWX7a04tRgpdhW_iofWuHqb_Ygp8fFsUkRjOK7_QyFQ Create a new OpenShift project to deploy our application, call it cloud-native-starter . oc new-project cloud-native-starter Build your application's image by running the oc new-build command from your source code root directory. This will create a Build and an ImageStream of the app. oc new-build --name authors --binary --strategy docker The output should look like below: $ oc new-build --name authors --binary --strategy docker * A Docker build using binary input will be created * The resulting image will be pushed to image stream tag \"authors:latest\" * A binary build was created, use 'start-build --from-dir' to trigger a new build --> Creating resources with label build = authors ... imagestream.image.openshift.io \"authors\" created buildconfig.build.openshift.io \"authors\" created --> Success Start a new build using the oc start-build command. oc start-build authors --from-dir . --follow The output should look like below: $ oc start-build authors --from-dir . --follow Uploading directory \".\" as binary input for the build ... . Uploading finished build.build.openshift.io/authors-1 started Receiving source from STDIN as archive ... Pulling image maven:3.5-jdk-8 ... Pulling image open-liberty:microProfile2-java11 ... Extracting --> FROM maven:3.5-jdk-8 as BUILD --> COPY src /usr/src/app/src --> COPY pom.xml /usr/src/app --> RUN mvn -f /usr/src/app/pom.xml clean package ... Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-clean-plugin/2.5/maven-clean-plugin-2.5.pom ... --> FROM open-liberty:microProfile2-java11 as 1 --> COPY liberty/server.xml /config/ --> COPY --from = BUILD /usr/src/app/target/authors.war /config/apps/ --> EXPOSE 3000 --> ENV \"OPENSHIFT_BUILD_NAME\" = \"authors-1\" \"OPENSHIFT_BUILD_NAMESPACE\" = \"cloud-native-starter\" --> LABEL \"io.openshift.build.name\" = \"authors-1\" \"io.openshift.build.namespace\" = \"cloud-native-starter\" --> Committing changes to temp.builder.openshift.io/cloud-native-starter/authors-1:534cb12a ... --> Done Pushing image docker-registry.default.svc:5000/cloud-native-starter/authors:latest ... Pushed 0 /13 layers, 8 % complete Pushed 1 /13 layers, 38 % complete ... Pushed 12 /13 layers, 100 % complete Pushed 13 /13 layers, 100 % complete View the build logs by running the oc logs command. oc logs bc/authors Finally, deploy the application by running oc new-app . oc new-app -i authors The output should look like below: $ oc new-app -i authors --> Found image d3dfc36 ( 5 minutes old ) in image stream \"cloud-native-starter/authors\" under tag \"latest\" for \"authors\" * This image will be deployed in deployment config \"authors\" * Ports 3000 /tcp, 9080 /tcp, 9443 /tcp will be load balanced by service \"authors\" * Other containers can access this service through the hostname \"authors\" --> Creating resources ... deploymentconfig.apps.openshift.io \"authors\" created service \"authors\" created --> Success Application is not exposed. You can expose services to the outside world by executing one or more of the commands below: 'oc expose svc/authors' Run 'oc status' to view your app View the deployment logs by running the oc logs command. oc logs dc/authors The output should look like: $ oc logs dc/authors Launching defaultServer ( Open Liberty 19 .0.0.10/wlp-1.0.33.cl191020191002-0300 ) on Eclipse OpenJ9 VM, version 11 .0.4+11 ( en_US ) [ AUDIT ] CWWKE0001I: The server defaultServer has been launched. [ AUDIT ] CWWKG0093A: Processing configuration drop-ins resource: /opt/ol/wlp/usr/servers/defaultServer/configDropins/defaults/keystore.xml [ AUDIT ] CWWKG0093A: Processing configuration drop-ins resource: /opt/ol/wlp/usr/servers/defaultServer/configDropins/defaults/open-default-port.xml [ AUDIT ] CWWKZ0058I: Monitoring dropins for applications. [ AUDIT ] CWWKS4104A: LTPA keys created in 2 .099 seconds. LTPA key file: /opt/ol/wlp/output/defaultServer/resources/security/ltpa.keys [ AUDIT ] CWPKI0803A: SSL certificate created in 4 .881 seconds. SSL key file: /opt/ol/wlp/output/defaultServer/resources/security/key.p12 Expose the service using oc expose , a route will be created. oc expose svc/authors Find the application's route by running oc get routes . oc get routes The output should look like below: $ oc get routes NAME HOST/PORT PATH SERVICES PORT TERMINATION WILDCARD authors authors-cloud-native-starter.aida-dev-apps-10-30-f2c6cdc6801be85fd188b09d006f13e3-0001.us-south.containers.appdomain.cloud authors 3000 -tcp None Copy the URL into a browser and append /openapi/ui . Also verify this works with curl by running curl -X GET \"http:// $( oc get route authors -o jsonpath ={ .spec.host } ) /api/v1/getauthor?name=Niklas%20Heidloff\" -H \"accept: application/json\" The output should look like the following: { \"name\" : \"Niklas Heidloff\" , \"twitter\" : \"https://twitter.com/nheidloff\" , \"blog\" : \"http://heidloff.net\" } Congratulations on completing this exercise!","title":"Lab 6b. Deploy a Java app with Build Config (CLI)"},{"location":"exercise-06b/#exercise-6b-deploy-a-java-application-with-build-config-cli-version","text":"In this exercise we'll revisit the application from exercise 1, except we'll use equivalent CLI commands to deploy our \"Authors\" application. From the IBM Cloud console launch the IBM Cloud Shell. Refer to our Getting Starting material to learn how to access the IBM Cloud Shell.","title":"Exercise 6b: Deploy a Java application with Build Config (CLI version)"},{"location":"exercise-06b/#deploy-authors-application-cli-version","text":"First, clone the Authors source code and change to that directory. git clone https://github.com/IBM/openshift-on-ibm-cloud-workshops cd openshift-on-ibm-cloud-workshops cd deploying-to-openshift Take note of the new Dockerfile in the application's directory. We've pre-written it for you. But we've copied it here too, go through each line and read the corresponding comment. # Use an official JDK image FROM maven:3.5-jdk-8 as BUILD # Copy the application source code COPY src /usr/src/app/src COPY pom.xml /usr/src/app # Run maven to build the application RUN mvn -f /usr/src/app/pom.xml clean package FROM open-liberty:microProfile2-java11 COPY liberty/server.xml /config/ COPY --from = BUILD /usr/src/app/target/authors.war /config/apps/ # Allow traffic on port 3000 EXPOSE 3000 From the OpenShift console click the user name in the top right corner and select Copy Login Command . The login command will be copied to the clipboard, in the IBM Cloud Shell, paste that command. For example: oc login https://c100-e.us-south.containers.cloud.ibm.com:30403 --token = jWX7a04tRgpdhW_iofWuHqb_Ygp8fFsUkRjOK7_QyFQ Create a new OpenShift project to deploy our application, call it cloud-native-starter . oc new-project cloud-native-starter Build your application's image by running the oc new-build command from your source code root directory. This will create a Build and an ImageStream of the app. oc new-build --name authors --binary --strategy docker The output should look like below: $ oc new-build --name authors --binary --strategy docker * A Docker build using binary input will be created * The resulting image will be pushed to image stream tag \"authors:latest\" * A binary build was created, use 'start-build --from-dir' to trigger a new build --> Creating resources with label build = authors ... imagestream.image.openshift.io \"authors\" created buildconfig.build.openshift.io \"authors\" created --> Success Start a new build using the oc start-build command. oc start-build authors --from-dir . --follow The output should look like below: $ oc start-build authors --from-dir . --follow Uploading directory \".\" as binary input for the build ... . Uploading finished build.build.openshift.io/authors-1 started Receiving source from STDIN as archive ... Pulling image maven:3.5-jdk-8 ... Pulling image open-liberty:microProfile2-java11 ... Extracting --> FROM maven:3.5-jdk-8 as BUILD --> COPY src /usr/src/app/src --> COPY pom.xml /usr/src/app --> RUN mvn -f /usr/src/app/pom.xml clean package ... Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-clean-plugin/2.5/maven-clean-plugin-2.5.pom ... --> FROM open-liberty:microProfile2-java11 as 1 --> COPY liberty/server.xml /config/ --> COPY --from = BUILD /usr/src/app/target/authors.war /config/apps/ --> EXPOSE 3000 --> ENV \"OPENSHIFT_BUILD_NAME\" = \"authors-1\" \"OPENSHIFT_BUILD_NAMESPACE\" = \"cloud-native-starter\" --> LABEL \"io.openshift.build.name\" = \"authors-1\" \"io.openshift.build.namespace\" = \"cloud-native-starter\" --> Committing changes to temp.builder.openshift.io/cloud-native-starter/authors-1:534cb12a ... --> Done Pushing image docker-registry.default.svc:5000/cloud-native-starter/authors:latest ... Pushed 0 /13 layers, 8 % complete Pushed 1 /13 layers, 38 % complete ... Pushed 12 /13 layers, 100 % complete Pushed 13 /13 layers, 100 % complete View the build logs by running the oc logs command. oc logs bc/authors Finally, deploy the application by running oc new-app . oc new-app -i authors The output should look like below: $ oc new-app -i authors --> Found image d3dfc36 ( 5 minutes old ) in image stream \"cloud-native-starter/authors\" under tag \"latest\" for \"authors\" * This image will be deployed in deployment config \"authors\" * Ports 3000 /tcp, 9080 /tcp, 9443 /tcp will be load balanced by service \"authors\" * Other containers can access this service through the hostname \"authors\" --> Creating resources ... deploymentconfig.apps.openshift.io \"authors\" created service \"authors\" created --> Success Application is not exposed. You can expose services to the outside world by executing one or more of the commands below: 'oc expose svc/authors' Run 'oc status' to view your app View the deployment logs by running the oc logs command. oc logs dc/authors The output should look like: $ oc logs dc/authors Launching defaultServer ( Open Liberty 19 .0.0.10/wlp-1.0.33.cl191020191002-0300 ) on Eclipse OpenJ9 VM, version 11 .0.4+11 ( en_US ) [ AUDIT ] CWWKE0001I: The server defaultServer has been launched. [ AUDIT ] CWWKG0093A: Processing configuration drop-ins resource: /opt/ol/wlp/usr/servers/defaultServer/configDropins/defaults/keystore.xml [ AUDIT ] CWWKG0093A: Processing configuration drop-ins resource: /opt/ol/wlp/usr/servers/defaultServer/configDropins/defaults/open-default-port.xml [ AUDIT ] CWWKZ0058I: Monitoring dropins for applications. [ AUDIT ] CWWKS4104A: LTPA keys created in 2 .099 seconds. LTPA key file: /opt/ol/wlp/output/defaultServer/resources/security/ltpa.keys [ AUDIT ] CWPKI0803A: SSL certificate created in 4 .881 seconds. SSL key file: /opt/ol/wlp/output/defaultServer/resources/security/key.p12 Expose the service using oc expose , a route will be created. oc expose svc/authors Find the application's route by running oc get routes . oc get routes The output should look like below: $ oc get routes NAME HOST/PORT PATH SERVICES PORT TERMINATION WILDCARD authors authors-cloud-native-starter.aida-dev-apps-10-30-f2c6cdc6801be85fd188b09d006f13e3-0001.us-south.containers.appdomain.cloud authors 3000 -tcp None Copy the URL into a browser and append /openapi/ui . Also verify this works with curl by running curl -X GET \"http:// $( oc get route authors -o jsonpath ={ .spec.host } ) /api/v1/getauthor?name=Niklas%20Heidloff\" -H \"accept: application/json\" The output should look like the following: { \"name\" : \"Niklas Heidloff\" , \"twitter\" : \"https://twitter.com/nheidloff\" , \"blog\" : \"http://heidloff.net\" } Congratulations on completing this exercise!","title":"Deploy Authors application (CLI version)"},{"location":"pre-work/CLOUD_SHELL/","text":"The IBM Cloud Shell: Using the CLI \u00b6 For this workshop we'll be using the IBM Cloud Shell. The IBM Cloud Shell is a cloud-based shell workspace that you can access through your browser. It's preconfigured with the full IBM Cloud CLI and tons of plug-ins, and other 3 rd party CLIs like OpenShift's oc , Helm's helm and Kubernetes' kubectl . Refer to the SETUP_CLI section if you wish to install these CLIs on your local machine. Accessing the IBM Cloud Shell \u00b6 From the IBM Cloud console, click the IBM Cloud Shell icon. A session will start and automatically log you in through the IBM Cloud CLI. NOTE Make sure you've selected the right account in the account list From here, you can access pre-installed CLIs like git , kubectl , and many others.","title":"Access the IBM Cloud Shell"},{"location":"pre-work/CLOUD_SHELL/#the-ibm-cloud-shell-using-the-cli","text":"For this workshop we'll be using the IBM Cloud Shell. The IBM Cloud Shell is a cloud-based shell workspace that you can access through your browser. It's preconfigured with the full IBM Cloud CLI and tons of plug-ins, and other 3 rd party CLIs like OpenShift's oc , Helm's helm and Kubernetes' kubectl . Refer to the SETUP_CLI section if you wish to install these CLIs on your local machine.","title":"The IBM Cloud Shell: Using the CLI"},{"location":"pre-work/CLOUD_SHELL/#accessing-the-ibm-cloud-shell","text":"From the IBM Cloud console, click the IBM Cloud Shell icon. A session will start and automatically log you in through the IBM Cloud CLI. NOTE Make sure you've selected the right account in the account list From here, you can access pre-installed CLIs like git , kubectl , and many others.","title":"Accessing the IBM Cloud Shell"},{"location":"pre-work/DOCKER/","text":"Docker \u00b6 To help you understand the basics of Docker technology we have created a tutorial where you will build and run a Node.js application with Docker. The application will translate phrases from one language to another by using Watson's Language Translator service. {% hint style=\"info\" %} Docker container technology separates applications from the underlying Operating System and infrastructure, which is an analog to VM technology that is separating an operating systems from the bare metal - server hardware. Docker technology emulates the Operating System (OS), making it possible to containerize only the application and dependencies, like libraries and binaries, by being packaged in an image. Running an image is much faster as now the OS is emulated. In addition, the image is now portable and can be shared between services. Creating your first containerized application with Docker \u00b6 In our tutorial, you'll be given the source code for the sample application, but to make it useful we'll need to provde an API key for the Language Translator service. Once we have have the API key we'll update the source code, containerize the application, run it, and test a few phrases. Let's get started! 0. Install Docker Locally \u00b6 Navigate to https://docs.docker.com/get-docker/ to download and install the lastest version of Docker for your OS of choice. 1. Create a Language Translator service \u00b6 Navigate to the IBM Cloud dashboard and click on \"Catalog\". Search for the \"Language Translator\" service, and click the corresponding tile. Choose to region and select the \"Lite\" (free of charge) plan, click the \"Create\" button. You will be redirected to the service's overview page. 2. Copy the Language Translator API key \u00b6 From the service's overview page, choose the \"Service Credentials\" option on the lefthand navigation bar. A credential containing an API key should be automatically create but if you do not see one, you can create a new credential. Save the API key somewhere for the next section in this workshop. The next steps will demonstrate on how to build a Dockerized Node.js application that provides an endpoint to translate phrases. 3. Clone the source code \u00b6 Open your local terminal and create a temporary directory to host the source code. cd ~ mkdir openshift-workshop cd openshift-workshop git clone https://github.com/IBM/node-docker-language-translation cd node-docker-language-translation 4. Build the application with Docker \u00b6 To build the application with Docker run the following: docker build . -t translator:v1 This command uses the Dockerfile in the base directory to download a Node.js 10 base image and install our application on top. Let's explore the contents of the Dockerfile ... FROM node:10 ... builds our image on top of the official Node.js 10 image. WORKDIR /usr/src/app ... creates a working directory for our application to live in. COPY package*.json ./ ... copies the source's package.json file to our working directory. RUN npm install ... installs our dependencies as defined in our package.json . COPY . . ... copies the rest of our source code into the working directory. EXPOSE 8080 ... exposes port 8080. CMD [ \"node\" , \"server.js\" ] ... starts the application. 5. Run the Docker image \u00b6 To run our application as a container, issue the following command with your Language Translator API key: docker run -p 8080 :8080 -e \"lt_key=<api_key>\" translator:v1 For example, here's what I used: docker run -p 8080 :8080 -e \"lt_key=T1ReDZISYE4cpqQnQHKTWe1F9iUy6hhxkRu0aWqzmxQ3\" translator:v1 6. Test the application \u00b6 curl \"localhost:8080/translate?text=how+are+you\" You should the following output: { \"translations\" : [ { \"translation\" : \"\u00bfC\u00f3mo est\u00e1s?\" } ], \"word_count\" : 3 , \"character_count\" : 11 } % The text is translated to Spanish by default. You can specify the langauge by passing in other language flags, for example: curl \"localhost:8080/translate?text=how+are+you?&lang=en-de\" You should the following output: { \"translations\" : [ { \"translation\" : \"Wie geht es Ihnen?\" } ], \"word_count\" : 3 , \"character_count\" : 12 } in Polish curl \"localhost:8080/translate?text=Let+us+learn+about+open+technology&lang=en-pl\" { \"translations\" : [ { \"translation\" : \"Dowiedz si\u0119 wi\u0119cej o otwartej technologii\" } ], \"word_count\" : 6 , \"character_count\" : 34 } You can see the supported languages (both from and to) in the Language Translator documentation . Congratulations! You just containerized a Node.js application that provides transation services. 7. Cleaning up \u00b6 To stop the container you need to first find the container ID, run the following command to find it: $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES d426e0fac2eb translator:v1 \"docker-entrypoint.s\u2026\" 8 minutes ago Up 8 minutes 0 .0.0.0:8080->8080/tcp strange_northcutt In the example above, the container ID is d426e0fac2eb . Stop the image with the following command, replacing the ID with your own. docker container stop d426e0fac2eb Run the following command to remove the container, replacing the ID with your own. docker container rm d426e0fac2eb 8. Removing the image \u00b6 You can now remove the image by running the following: docker image rm translator:v1 You should output similar to what is seen below: docker image rm translator:v1 Untagged: translator:v1 Deleted: sha256:96afe0ca495e050f1cdabe79969675b3be49f6047525bd0f55061e761b176fed Deleted: sha256:f9e94a5182f73c90d1ef85d6516e012d5c08bfc5cb2f720862c0a35519aac9b6 Deleted: sha256:e2e85574bc230465e32e61375ec378a2e525042390766f747bf81b2b88e90a99 Deleted: sha256:fcf8c21a74d01e5f40e2ef8cef30237ac806e0f00d0d703499b2d073f3552d16 Deleted: sha256:610798de09748a80456726a693f3ddb019c322b30e144512a15a594a4744d995 Deleted: sha256:896aab822576a1fd8090e7c2586ec4e4d1c1ec680bf370bcfe9390f2c7eebead Deleted: sha256:0e45a616772f2b2703d6127f27b77d73bec69fdfa1e3cac543d1a17f52e23da8 Deleted: sha256:9b19cb8e4886f8f3c735a549309936de7283b09171ec36ecc6caa498fea2330c Deleted: sha256:0f00eb5804174d4b42cc70e5e7c412ba52b913d25fd39d66a4b1286486da86d6 Deleted: sha256:2c610224d2f2aeed545ab8dd1377d6cbec5767da84d196e365c21171b380d212 Congratulations on creating your first containerized application! Troubleshooting \u00b6 You can check your container's logs by running: docker logs <container_id> For example... $ docker logs 4450279a9f50 Running on http://0.0.0.0:8080 No language passed to translate to. Converting to Spanish by default. { \"translations\" : [ { \"translation\" : \"Hola\" } ] , \"word_count\" : 1 , \"character_count\" : 5 }","title":"General Docker Tutorial"},{"location":"pre-work/DOCKER/#docker","text":"To help you understand the basics of Docker technology we have created a tutorial where you will build and run a Node.js application with Docker. The application will translate phrases from one language to another by using Watson's Language Translator service. {% hint style=\"info\" %} Docker container technology separates applications from the underlying Operating System and infrastructure, which is an analog to VM technology that is separating an operating systems from the bare metal - server hardware. Docker technology emulates the Operating System (OS), making it possible to containerize only the application and dependencies, like libraries and binaries, by being packaged in an image. Running an image is much faster as now the OS is emulated. In addition, the image is now portable and can be shared between services.","title":"Docker"},{"location":"pre-work/DOCKER/#creating-your-first-containerized-application-with-docker","text":"In our tutorial, you'll be given the source code for the sample application, but to make it useful we'll need to provde an API key for the Language Translator service. Once we have have the API key we'll update the source code, containerize the application, run it, and test a few phrases. Let's get started!","title":"Creating your first containerized application with Docker"},{"location":"pre-work/DOCKER/#0-install-docker-locally","text":"Navigate to https://docs.docker.com/get-docker/ to download and install the lastest version of Docker for your OS of choice.","title":"0. Install Docker Locally"},{"location":"pre-work/DOCKER/#1-create-a-language-translator-service","text":"Navigate to the IBM Cloud dashboard and click on \"Catalog\". Search for the \"Language Translator\" service, and click the corresponding tile. Choose to region and select the \"Lite\" (free of charge) plan, click the \"Create\" button. You will be redirected to the service's overview page.","title":"1. Create a Language Translator service"},{"location":"pre-work/DOCKER/#2-copy-the-language-translator-api-key","text":"From the service's overview page, choose the \"Service Credentials\" option on the lefthand navigation bar. A credential containing an API key should be automatically create but if you do not see one, you can create a new credential. Save the API key somewhere for the next section in this workshop. The next steps will demonstrate on how to build a Dockerized Node.js application that provides an endpoint to translate phrases.","title":"2. Copy the Language Translator API key"},{"location":"pre-work/DOCKER/#3-clone-the-source-code","text":"Open your local terminal and create a temporary directory to host the source code. cd ~ mkdir openshift-workshop cd openshift-workshop git clone https://github.com/IBM/node-docker-language-translation cd node-docker-language-translation","title":"3. Clone the source code"},{"location":"pre-work/DOCKER/#4-build-the-application-with-docker","text":"To build the application with Docker run the following: docker build . -t translator:v1 This command uses the Dockerfile in the base directory to download a Node.js 10 base image and install our application on top. Let's explore the contents of the Dockerfile ... FROM node:10 ... builds our image on top of the official Node.js 10 image. WORKDIR /usr/src/app ... creates a working directory for our application to live in. COPY package*.json ./ ... copies the source's package.json file to our working directory. RUN npm install ... installs our dependencies as defined in our package.json . COPY . . ... copies the rest of our source code into the working directory. EXPOSE 8080 ... exposes port 8080. CMD [ \"node\" , \"server.js\" ] ... starts the application.","title":"4. Build the application with Docker"},{"location":"pre-work/DOCKER/#5-run-the-docker-image","text":"To run our application as a container, issue the following command with your Language Translator API key: docker run -p 8080 :8080 -e \"lt_key=<api_key>\" translator:v1 For example, here's what I used: docker run -p 8080 :8080 -e \"lt_key=T1ReDZISYE4cpqQnQHKTWe1F9iUy6hhxkRu0aWqzmxQ3\" translator:v1","title":"5. Run the Docker image"},{"location":"pre-work/DOCKER/#6-test-the-application","text":"curl \"localhost:8080/translate?text=how+are+you\" You should the following output: { \"translations\" : [ { \"translation\" : \"\u00bfC\u00f3mo est\u00e1s?\" } ], \"word_count\" : 3 , \"character_count\" : 11 } % The text is translated to Spanish by default. You can specify the langauge by passing in other language flags, for example: curl \"localhost:8080/translate?text=how+are+you?&lang=en-de\" You should the following output: { \"translations\" : [ { \"translation\" : \"Wie geht es Ihnen?\" } ], \"word_count\" : 3 , \"character_count\" : 12 } in Polish curl \"localhost:8080/translate?text=Let+us+learn+about+open+technology&lang=en-pl\" { \"translations\" : [ { \"translation\" : \"Dowiedz si\u0119 wi\u0119cej o otwartej technologii\" } ], \"word_count\" : 6 , \"character_count\" : 34 } You can see the supported languages (both from and to) in the Language Translator documentation . Congratulations! You just containerized a Node.js application that provides transation services.","title":"6. Test the application"},{"location":"pre-work/DOCKER/#7-cleaning-up","text":"To stop the container you need to first find the container ID, run the following command to find it: $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES d426e0fac2eb translator:v1 \"docker-entrypoint.s\u2026\" 8 minutes ago Up 8 minutes 0 .0.0.0:8080->8080/tcp strange_northcutt In the example above, the container ID is d426e0fac2eb . Stop the image with the following command, replacing the ID with your own. docker container stop d426e0fac2eb Run the following command to remove the container, replacing the ID with your own. docker container rm d426e0fac2eb","title":"7. Cleaning up"},{"location":"pre-work/DOCKER/#8-removing-the-image","text":"You can now remove the image by running the following: docker image rm translator:v1 You should output similar to what is seen below: docker image rm translator:v1 Untagged: translator:v1 Deleted: sha256:96afe0ca495e050f1cdabe79969675b3be49f6047525bd0f55061e761b176fed Deleted: sha256:f9e94a5182f73c90d1ef85d6516e012d5c08bfc5cb2f720862c0a35519aac9b6 Deleted: sha256:e2e85574bc230465e32e61375ec378a2e525042390766f747bf81b2b88e90a99 Deleted: sha256:fcf8c21a74d01e5f40e2ef8cef30237ac806e0f00d0d703499b2d073f3552d16 Deleted: sha256:610798de09748a80456726a693f3ddb019c322b30e144512a15a594a4744d995 Deleted: sha256:896aab822576a1fd8090e7c2586ec4e4d1c1ec680bf370bcfe9390f2c7eebead Deleted: sha256:0e45a616772f2b2703d6127f27b77d73bec69fdfa1e3cac543d1a17f52e23da8 Deleted: sha256:9b19cb8e4886f8f3c735a549309936de7283b09171ec36ecc6caa498fea2330c Deleted: sha256:0f00eb5804174d4b42cc70e5e7c412ba52b913d25fd39d66a4b1286486da86d6 Deleted: sha256:2c610224d2f2aeed545ab8dd1377d6cbec5767da84d196e365c21171b380d212 Congratulations on creating your first containerized application!","title":"8. Removing the image"},{"location":"pre-work/DOCKER/#troubleshooting","text":"You can check your container's logs by running: docker logs <container_id> For example... $ docker logs 4450279a9f50 Running on http://0.0.0.0:8080 No language passed to translate to. Converting to Spanish by default. { \"translations\" : [ { \"translation\" : \"Hola\" } ] , \"word_count\" : 1 , \"character_count\" : 5 }","title":"Troubleshooting"},{"location":"pre-work/GET_STARTED/","text":"Creating your IBM account and Accessing your OpenShift cluster \u00b6 In this section, you will login to your own IBM Cloud account, and then get access to a IBM Cloud Lab account which contains pre-provisioned clusters. Each lab attendee will be granted access to one cluster. Setting up your IBM Cloud ID \u00b6 Log into IBM Cloud with an existing account: https://cloud.ibm.com OR Create your own: http://cloud.ibm.com/registration Accessing the Cluster \u00b6 Instructors will provide a URL to a web app. Enter your IBMid (the email you used to sign up) and the lab key (also provided by the instructor). Follow the instructions on the next page. You will be added to the IBM Workshop account and granted access to a cluster. Note the name of your cluster. In the example below, it's TorontoMulticlientWorkshop31 . Back in IBM Cloud, refresh the IBM Cloud Dashboard . If required, switch to the 1840867-IBM account by clicking on the account selection drop down in the top nav bar. Click on Clusters in the Resource Summary tile. Under Clusters , click on the cluster that has been assigned to you. Launch the OpenShift web console and have a look around! You can come back to this dashboard throughout your lab.","title":"Create an IBM Cloud Account"},{"location":"pre-work/GET_STARTED/#creating-your-ibm-account-and-accessing-your-openshift-cluster","text":"In this section, you will login to your own IBM Cloud account, and then get access to a IBM Cloud Lab account which contains pre-provisioned clusters. Each lab attendee will be granted access to one cluster.","title":"Creating your IBM account and Accessing your OpenShift cluster"},{"location":"pre-work/GET_STARTED/#setting-up-your-ibm-cloud-id","text":"Log into IBM Cloud with an existing account: https://cloud.ibm.com OR Create your own: http://cloud.ibm.com/registration","title":"Setting up your IBM Cloud ID"},{"location":"pre-work/GET_STARTED/#accessing-the-cluster","text":"Instructors will provide a URL to a web app. Enter your IBMid (the email you used to sign up) and the lab key (also provided by the instructor). Follow the instructions on the next page. You will be added to the IBM Workshop account and granted access to a cluster. Note the name of your cluster. In the example below, it's TorontoMulticlientWorkshop31 . Back in IBM Cloud, refresh the IBM Cloud Dashboard . If required, switch to the 1840867-IBM account by clicking on the account selection drop down in the top nav bar. Click on Clusters in the Resource Summary tile. Under Clusters , click on the cluster that has been assigned to you. Launch the OpenShift web console and have a look around! You can come back to this dashboard throughout your lab.","title":"Accessing the Cluster"},{"location":"pre-work/KUBERNETES/","text":"Kubernetes Basics \u00b6 A Kubernetes cluster consists of a set of worker machines, called nodes, that run containerized applications. The worker node(s) host the Pods that are the components of the application workload. The control plane manages the worker nodes and the Pods in the cluster. In production environments, the control plane usually runs across multiple computers and a cluster usually runs multiple nodes, providing fault-tolerance and high availability. The kube-api-server , or API Server in short, is the brain of the Kubernetes cluster. In this lab, we'll be executing various Kubernetes commands/operations by using the powerful kubectl CLI which will talk to the API Server. It is possible to access the API Server via REST calls or officially supported client libraries but kubectl CLI is the most common and preferred way. Reference: Kubernetes Docs Checking access to a Kubernetes cluster \u00b6 kubectl version --short If the above command returns the Kubernetes version, you're good to go. You're free to use any managed Kubernetes service or local Kubernetes installation for this lab. Deploying a microservices app on Kubernetes \u00b6 The following command creates a Kubernetes Deployment called dewans-app from dewandemo/authors image (which is on Docker Hub). kubectl create deployment dewans-app --image = index.docker.io/dewandemo/authors:v1 One of the powerful feature of Kubernetes is the ability to scale your deployment up or down. The following command scales up dewans-app deployment to three repliacas . kubectl scale deployment dewans-app --replicas = 3 Execute the following command to view the running pods: kubectl get pods If you don't have any previous pods running on your system, you should see three pods running. Self-healing of Kubernetes \u00b6 From the output of the last command you ran, you should see a list like below: dewans-app-cf48574d-6cssh 1 /1 Running 0 10m dewans-app-cf48574d-c97hr 1 /1 Running 0 9m4s dewans-app-cf48574d-pqssh 1 /1 Running 0 9m4s Delete one of the pods: kubectl delete pods dewans-app-cf48574d-6cssh After few moments, execute the following command and you should still see three running pods. kubectl get pods Kubernetes deleted one of the pods but the deployment ensures a replica of three at all times so another pod was spun up. Updating the deployment with newer version of image \u00b6 kubectl set image deployment/dewans-app authors = index.docker.io/dewandemo/authors:v2 This is how easily you can update a deployment to use a newer (or older) image.","title":"Kubernetes Overview"},{"location":"pre-work/KUBERNETES/#kubernetes-basics","text":"A Kubernetes cluster consists of a set of worker machines, called nodes, that run containerized applications. The worker node(s) host the Pods that are the components of the application workload. The control plane manages the worker nodes and the Pods in the cluster. In production environments, the control plane usually runs across multiple computers and a cluster usually runs multiple nodes, providing fault-tolerance and high availability. The kube-api-server , or API Server in short, is the brain of the Kubernetes cluster. In this lab, we'll be executing various Kubernetes commands/operations by using the powerful kubectl CLI which will talk to the API Server. It is possible to access the API Server via REST calls or officially supported client libraries but kubectl CLI is the most common and preferred way. Reference: Kubernetes Docs","title":"Kubernetes Basics"},{"location":"pre-work/KUBERNETES/#checking-access-to-a-kubernetes-cluster","text":"kubectl version --short If the above command returns the Kubernetes version, you're good to go. You're free to use any managed Kubernetes service or local Kubernetes installation for this lab.","title":"Checking access to a Kubernetes cluster"},{"location":"pre-work/KUBERNETES/#deploying-a-microservices-app-on-kubernetes","text":"The following command creates a Kubernetes Deployment called dewans-app from dewandemo/authors image (which is on Docker Hub). kubectl create deployment dewans-app --image = index.docker.io/dewandemo/authors:v1 One of the powerful feature of Kubernetes is the ability to scale your deployment up or down. The following command scales up dewans-app deployment to three repliacas . kubectl scale deployment dewans-app --replicas = 3 Execute the following command to view the running pods: kubectl get pods If you don't have any previous pods running on your system, you should see three pods running.","title":"Deploying a microservices app on Kubernetes"},{"location":"pre-work/KUBERNETES/#self-healing-of-kubernetes","text":"From the output of the last command you ran, you should see a list like below: dewans-app-cf48574d-6cssh 1 /1 Running 0 10m dewans-app-cf48574d-c97hr 1 /1 Running 0 9m4s dewans-app-cf48574d-pqssh 1 /1 Running 0 9m4s Delete one of the pods: kubectl delete pods dewans-app-cf48574d-6cssh After few moments, execute the following command and you should still see three running pods. kubectl get pods Kubernetes deleted one of the pods but the deployment ensures a replica of three at all times so another pod was spun up.","title":"Self-healing of Kubernetes"},{"location":"pre-work/KUBERNETES/#updating-the-deployment-with-newer-version-of-image","text":"kubectl set image deployment/dewans-app authors = index.docker.io/dewandemo/authors:v2 This is how easily you can update a deployment to use a newer (or older) image.","title":"Updating the deployment with newer version of image"},{"location":"pre-work/SETUP_CLI/","text":"Setup CLI Access for the cluster \u00b6 This section documents how to set up CLI access to a cluster. If you do not already have access to a cluster, refer back to the Getting Started section. Install OpenShift CLI tools \u00b6 The oc CLI will be the main mechanism to interact with your OpenShift cluster. We'll be downloading and installing the CLI, and adding it to your environment path. NOTE : Check for newer releases on the OpenShift Origin Releases page. Download the oc tarball. wget https://github.com/openshift/origin/releases/download/v3.11.0/openshift-origin-client-tools-v3.11.0-0cbc58b-linux-64bit.tar.gz Unpack the tarball tar -xvzf openshift-origin-client-tools-v3.11.0-0cbc58b-linux-64bit.tar.gz Rename it for ease of use mv openshift-origin-client-tools-v3.11.0-0cbc58b-linux-64bit ${ HOME } /oc-cli Update PATH . NOTE : If you restart your cloud shell, you may need to re-run this command. export PATH = ${ PATH } : ${ HOME } /oc-cli Verify the utility is available by using which and the help command. which oc oc help Access the OpenShift Web Console \u00b6 To launch the OpenShift web console, navigate to the IBM Cloud Clusters Dashboard , find your cluster, and click on it. Click on OpenShift web console on the top right to launch the web console. Once in the OpenShift web console, click on the email/ID in the upper right. Choose the Copy Login Command option. Access your cluster using the oc CLI \u00b6 In a new termimal, paste the login command you copied from the web console. oc login https://c100-e.us-south.containers.cloud.ibm.com:30360 --token = NYVkVysxxxxxxxxxxxxxxxxxxxxRQa8tM You should see a success message similar to the one below: oc login https://c100-e.us-south.containers.cloud.ibm.com:30360 --token = NYVkVysxxxxxxxxxxxxxxxxxxxxRQa8tM Logged into \"https://c100-e.us-south.containers.cloud.ibm.com:30360\" as \"IAM#stevemar@ca.ibm.com\" using the token provided. You have access to the following projects and can switch between them with 'oc project <projectname>' Validate cluster access using oc commands \u00b6 View nodes in the cluster. oc get node View services, deployments, and pods. oc get svc,deploy,po --all-namespaces View projects oc get projects","title":"Setup OC CLI"},{"location":"pre-work/SETUP_CLI/#setup-cli-access-for-the-cluster","text":"This section documents how to set up CLI access to a cluster. If you do not already have access to a cluster, refer back to the Getting Started section.","title":"Setup CLI Access for the cluster"},{"location":"pre-work/SETUP_CLI/#install-openshift-cli-tools","text":"The oc CLI will be the main mechanism to interact with your OpenShift cluster. We'll be downloading and installing the CLI, and adding it to your environment path. NOTE : Check for newer releases on the OpenShift Origin Releases page. Download the oc tarball. wget https://github.com/openshift/origin/releases/download/v3.11.0/openshift-origin-client-tools-v3.11.0-0cbc58b-linux-64bit.tar.gz Unpack the tarball tar -xvzf openshift-origin-client-tools-v3.11.0-0cbc58b-linux-64bit.tar.gz Rename it for ease of use mv openshift-origin-client-tools-v3.11.0-0cbc58b-linux-64bit ${ HOME } /oc-cli Update PATH . NOTE : If you restart your cloud shell, you may need to re-run this command. export PATH = ${ PATH } : ${ HOME } /oc-cli Verify the utility is available by using which and the help command. which oc oc help","title":"Install OpenShift CLI tools"},{"location":"pre-work/SETUP_CLI/#access-the-openshift-web-console","text":"To launch the OpenShift web console, navigate to the IBM Cloud Clusters Dashboard , find your cluster, and click on it. Click on OpenShift web console on the top right to launch the web console. Once in the OpenShift web console, click on the email/ID in the upper right. Choose the Copy Login Command option.","title":"Access the OpenShift Web Console"},{"location":"pre-work/SETUP_CLI/#access-your-cluster-using-the-oc-cli","text":"In a new termimal, paste the login command you copied from the web console. oc login https://c100-e.us-south.containers.cloud.ibm.com:30360 --token = NYVkVysxxxxxxxxxxxxxxxxxxxxRQa8tM You should see a success message similar to the one below: oc login https://c100-e.us-south.containers.cloud.ibm.com:30360 --token = NYVkVysxxxxxxxxxxxxxxxxxxxxRQa8tM Logged into \"https://c100-e.us-south.containers.cloud.ibm.com:30360\" as \"IAM#stevemar@ca.ibm.com\" using the token provided. You have access to the following projects and can switch between them with 'oc project <projectname>'","title":"Access your cluster using the oc CLI"},{"location":"pre-work/SETUP_CLI/#validate-cluster-access-using-oc-commands","text":"View nodes in the cluster. oc get node View services, deployments, and pods. oc get svc,deploy,po --all-namespaces View projects oc get projects","title":"Validate cluster access using oc commands"},{"location":"resources/","text":"Additional resources \u00b6 Certification on CognitiveClass.ai IBM Developer Docs: Red Hat OpenShift on IBM Cloud Survey \u00b6 Tell us how we did","title":"Additional resources"},{"location":"resources/#additional-resources","text":"Certification on CognitiveClass.ai IBM Developer Docs: Red Hat OpenShift on IBM Cloud","title":"Additional resources"},{"location":"resources/#survey","text":"Tell us how we did","title":"Survey"}]}